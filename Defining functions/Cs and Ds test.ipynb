{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2c7b729",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "784a0602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3a17e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the functions\n",
    "\n",
    "from functions_py_file import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1840374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "\n",
    "adjacency_matrix = pd.read_csv(\"adjacency_matrix2.csv\", header=0, index_col=0)\n",
    "\n",
    "multilevel = pd.read_csv(\"multilevel2.csv\", header=0, index_col=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03020fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the adjacency matrix\n",
    "adjacency_matrix = clean_adjacency_mat(adjacency_matrix)\n",
    "\n",
    "# Clean the multilevel lookup table\n",
    "multilevel = clean_multilevel(multilevel, adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d755a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the subset adjacency matrix\n",
    "\n",
    "subset_leaf_list = [\"Amyg_L_73_1\", \"Hippo_L_75_1\"]\n",
    "subset = subset_matrix_creator(subset_leaf_list, adjacency_matrix, multilevel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "207c1cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the descendants matrix\n",
    "descendants = adjacency_descendants(subset, N=20, mu=3.0)\n",
    "\n",
    "# Create the ancestors matrix\n",
    "ancestors = adjacency_ancestors(subset, N=20, mu=3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db47dc5a",
   "metadata": {},
   "source": [
    "## 2. Generate data for calculating Ds and Cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddf9225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate simulated data\n",
    "\n",
    "generate_simulated_data(filename=\"test1_data.npz\", subset=subset, case=1, n_repeats=10, N=20, mu=3.0)\n",
    "generate_simulated_data(filename=\"test2_data.npz\", subset=subset, case=2, n_repeats=10, N=20, mu=3.0)\n",
    "generate_simulated_data(filename=\"test3_data.npz\", subset=subset, case=3, n_repeats=10, N=20, mu=3.0)\n",
    "generate_simulated_data(filename=\"test4_data.npz\", subset=subset, case=4, n_repeats=10, N=20, mu=3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dcd892",
   "metadata": {},
   "source": [
    "## 3. Calculating Ds (our version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25255450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify our current permutation testing function to have outputs \n",
    "\n",
    "def permutation_testing(filename_old, filename_new, subset, n_repeats, nperm, N, mu, niter, clip, initial_prob):\n",
    "    ''' Function that conducts permutation testing\n",
    "    \n",
    "    This function conducts permutation testing using the generated data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename_old: string\n",
    "        The pattern of the filenames of the generated data; example: \"test1_data_repeat_*\"\n",
    "    \n",
    "    filename_new: string\n",
    "        The user-specified filename pattern for the permutation testing results (choose a different name from \n",
    "        filename_old, i.e. say \"results\" instead of \"data\" if you don't want generated data to get overwritten \n",
    "        by permutation testing results); example: \"results.npz\"\n",
    "    \n",
    "    subset: pandas.DataFrame\n",
    "        The subset adjacency matrix\n",
    "    \n",
    "    n_repeats: int\n",
    "        The number of repeats. We generated a random dataset with the same parameters but `n_repeats` \n",
    "        different realizations of the random variables. `n_repeats` must be the same value as `n_repeats`\n",
    "        when we generated data earlier. n_repeats should be 1 in practice for external users, but in our case, \n",
    "        since we simulated a lot of data, n_repeats is greater than 1.\n",
    "    \n",
    "    nperm: int\n",
    "        The number of permutations for permutation testing \n",
    "    \n",
    "    N: int\n",
    "        The number of samples. N must be the same value as N from generating data earlier.\n",
    "    \n",
    "    mu: float\n",
    "        The difference in means (generally unknown). mu should be the same value as mu from generating data\n",
    "        earlier in order to get meaningful results. But, mu doesn't have to be the same if you don't want to\n",
    "        make it the same.\n",
    "    \n",
    "    niter: int\n",
    "        The number of iterations of the EM algorithm\n",
    "    \n",
    "    clip: float\n",
    "        Number that clips probabilities away from 0 or 1\n",
    "    \n",
    "    initial_prob: float\n",
    "        The intial probability\n",
    "    \n",
    "    Returns \n",
    "    ----------\n",
    "    npz file (written to disk, not explicitly returned)\n",
    "        The 1st array contains p-values, 2nd array contains the names of the structures in the subset, 3rd \n",
    "        array contains the posterior probabilities, and 4th array contains the information from the prior 3 \n",
    "        arrays saved in 1 string per structure.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    M = subset.shape[0] # Number of total unique structures\n",
    "    S = np.array(subset, dtype = bool)\n",
    "    names_subset = subset.columns # List of the 8 structures' names\n",
    "    Descendants = adjacency_descendants(subset, N=N, mu=mu)\n",
    "    Descendants_and_self = np.logical_or(Descendants, np.eye(M))\n",
    "    \n",
    "    basename, extension = os.path.splitext(filename_new)\n",
    "    filename_old = glob(filename_old)\n",
    "    filename_old = sorted(filename_old)\n",
    "    \n",
    "    for j in range(n_repeats):\n",
    "        \n",
    "        # Load the generated data for each repeat\n",
    "        data = np.load(filename_old[j])\n",
    "        X = data[\"X\"]\n",
    "        Z = data[\"Z\"]\n",
    "        G = data[\"G\"]\n",
    "        \n",
    "        outputs = [] # Empty list for each iteration\n",
    "        \n",
    "        ### PARAMETER ESTIMATION ###\n",
    "    \n",
    "        P_subset = np.ones(M) * 0.5 # Array of 8 copies of 0.5\n",
    "        Q = Q_from_P(P_subset, S)\n",
    "\n",
    "        P0 = np.ones(M) * initial_prob\n",
    "        P_subset = estimate_P(X[G], mu, S, Descendants_and_self, draw=0, P0=P0, niter=niter, names=names_subset, clip=clip)\n",
    "        # Set draw = 0 to prevent drawing the graphs\n",
    "        \n",
    "        ### GENERATING PERMUTED DATA ###\n",
    "    \n",
    "        Ps = []\n",
    "        for n in range(nperm):\n",
    "            Xp = X[np.random.permutation(N)[G]]\n",
    "            P_ = estimate_P(Xp,mu,S,Descendants_and_self,draw=0,niter=niter,P0=P0)\n",
    "            Ps.append(P_)\n",
    "\n",
    "        Ps_sort = np.array([np.sort(Pi)[::-1] for Pi in Ps])\n",
    "        \n",
    "        ### PERMUTATION TESTING ###\n",
    "    \n",
    "        inds = np.argsort(P_subset)[::-1]\n",
    "        pval = np.zeros_like(P_subset)\n",
    "        alpha = 0.05\n",
    "        \n",
    "        pval_list = [] # Empty list to be filled\n",
    "        names_list = [] # Empty list to be filled\n",
    "        posterior_list = [] # Empty list to be filled\n",
    "        \n",
    "        for i in range(M):    \n",
    "            pval[inds[i]] = np.mean(Ps_sort[:,i] >= P_subset[inds[i]])\n",
    "            outputs.append(f\"{names_subset[inds[i]]}, P[Z=1|X]={P_subset[inds[i]]}, p={pval[inds[i]]}\")\n",
    "            # Every structure that gets rejected gets an entry\n",
    "            \n",
    "            pval_list.append(pval[inds[i]])\n",
    "            names_list.append(names_subset[inds[i]])\n",
    "            posterior_list.append(P_subset[inds[i]])\n",
    "        \n",
    "        ### SORT THE POSTERIOR VALUES ###\n",
    "        \n",
    "        # Use the subset adjacency matrix to create a dictionary\n",
    "        columns = np.array(subset.columns)\n",
    "        dictionary = dict(enumerate(columns.flatten(), 1))\n",
    "        dictionary = dict((value, key) for key, value in dictionary.items()) # Swap the keys and values\n",
    "        outputs = sorting_function(outputs, dictionary)\n",
    "        \n",
    "        ### SAVE DATA ### \n",
    "        \n",
    "        filename_new_this_repeat = basename + f'_repeat_{j:06d}' + extension\n",
    "        np.savez(filename_new_this_repeat, pval = pval_list, names = names_list, posterior = posterior_list, strings = outputs)\n",
    "        \n",
    "        ### OUTPUTS ###\n",
    "        \n",
    "        return np.quantile(Ps_sort, 0.95, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52bb49e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDs for test 1:\u001b[0m\n",
      "[0.1894531  0.1894531  0.1894531  0.1894531  0.08984659 0.08984659\n",
      " 0.00126238 0.00126238]\n",
      "\n",
      "\n",
      "\u001b[1mDs for test 2:\u001b[0m\n",
      "[5.99138136e-01 5.99138136e-01 5.99138136e-01 5.99138136e-01\n",
      " 5.72739619e-01 5.72739619e-01 1.72202632e-04 1.72202632e-04]\n",
      "\n",
      "\n",
      "\u001b[1mDs for test 3:\u001b[0m\n",
      "[0.85154346 0.85154346 0.85154346 0.85154346 0.78849059 0.78849059\n",
      " 0.7298553  0.7298553 ]\n",
      "\n",
      "\n",
      "\u001b[1mDs for test 4:\u001b[0m\n",
      "[0.86350713 0.86350713 0.86350713 0.86350713 0.37892168 0.37892168\n",
      " 0.27892163 0.27892163]\n"
     ]
    }
   ],
   "source": [
    "# Permutation testing\n",
    "\n",
    "print(\"\\033[1m\" + \"Ds for test 1:\" + \"\\033[0m\")\n",
    "print(permutation_testing(filename_old=\"test1_data_repeat_*\", filename_new = \"test1_results.npz\", subset=subset, n_repeats=10, nperm=10, N=20, mu=3.0, niter=5, initial_prob = 0.5, clip=0.001))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"\\033[1m\" + \"Ds for test 2:\" + \"\\033[0m\")\n",
    "print(permutation_testing(filename_old=\"test2_data_repeat_*\", filename_new = \"test2_results.npz\", subset=subset, n_repeats=10, nperm=10, N=20, mu=3.0, niter=5, clip=0.0001, initial_prob = 0.5))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"\\033[1m\" + \"Ds for test 3:\" + \"\\033[0m\")\n",
    "print(permutation_testing(filename_old=\"test3_data_repeat_*\", filename_new = \"test3_results.npz\", subset=subset, n_repeats=10, nperm=10, N=20, mu=3.0, niter=5, initial_prob = 0.25, clip=0.01))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"\\033[1m\" + \"Ds for test 4:\" + \"\\033[0m\")\n",
    "print(permutation_testing(filename_old=\"test4_data_repeat_*\", filename_new = \"test4_results.npz\", subset=subset, n_repeats=10, nperm=10, N=20, mu=3.0, niter=5, initial_prob = 0.75, clip=0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc02c6b",
   "metadata": {},
   "source": [
    "## 4. Calculating Cs (based on the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ea67f235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified permutation testing function\n",
    "\n",
    "def permutation_testing2(filename_old, filename_new, subset, n_repeats, nperm, N, mu, niter, clip, initial_prob):\n",
    "    ''' Function that conducts permutation testing\n",
    "    \n",
    "    This function conducts permutation testing using the generated data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename_old: string\n",
    "        The pattern of the filenames of the generated data; example: \"test1_data_repeat_*\"\n",
    "    \n",
    "    filename_new: string\n",
    "        The user-specified filename pattern for the permutation testing results (choose a different name from \n",
    "        filename_old, i.e. say \"results\" instead of \"data\" if you don't want generated data to get overwritten \n",
    "        by permutation testing results); example: \"results.npz\"\n",
    "    \n",
    "    subset: pandas.DataFrame\n",
    "        The subset adjacency matrix\n",
    "    \n",
    "    n_repeats: int\n",
    "        The number of repeats. We generated a random dataset with the same parameters but `n_repeats` \n",
    "        different realizations of the random variables. `n_repeats` must be the same value as `n_repeats`\n",
    "        when we generated data earlier. n_repeats should be 1 in practice for external users, but in our case, \n",
    "        since we simulated a lot of data, n_repeats is greater than 1.\n",
    "    \n",
    "    nperm: int\n",
    "        The number of permutations for permutation testing \n",
    "    \n",
    "    N: int\n",
    "        The number of samples. N must be the same value as N from generating data earlier.\n",
    "    \n",
    "    mu: float\n",
    "        The difference in means (generally unknown). mu should be the same value as mu from generating data\n",
    "        earlier in order to get meaningful results. But, mu doesn't have to be the same if you don't want to\n",
    "        make it the same.\n",
    "    \n",
    "    niter: int\n",
    "        The number of iterations of the EM algorithm\n",
    "    \n",
    "    clip: float\n",
    "        Number that clips probabilities away from 0 or 1\n",
    "    \n",
    "    initial_prob: float\n",
    "        The intial probability\n",
    "    \n",
    "    Returns \n",
    "    ----------\n",
    "    npz file (written to disk, not explicitly returned)\n",
    "        The 1st array contains p-values, 2nd array contains the names of the structures in the subset, 3rd \n",
    "        array contains the posterior probabilities, and 4th array contains the information from the prior 3 \n",
    "        arrays saved in 1 string per structure.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    M = subset.shape[0] # Number of total unique structures\n",
    "    S = np.array(subset, dtype = bool)\n",
    "    names_subset = subset.columns # List of the 8 structures' names\n",
    "    Descendants = adjacency_descendants(subset, N=N, mu=mu)\n",
    "    Descendants_and_self = np.logical_or(Descendants, np.eye(M))\n",
    "    \n",
    "    basename, extension = os.path.splitext(filename_new)\n",
    "    filename_old = glob(filename_old)\n",
    "    filename_old = sorted(filename_old)\n",
    "    \n",
    "    for j in range(n_repeats):\n",
    "        \n",
    "        # Load the generated data for each repeat\n",
    "        data = np.load(filename_old[j])\n",
    "        X = data[\"X\"]\n",
    "        Z = data[\"Z\"]\n",
    "        G = data[\"G\"]\n",
    "        \n",
    "        outputs = [] # Empty list for each iteration\n",
    "        \n",
    "        ### PARAMETER ESTIMATION ###\n",
    "    \n",
    "        P_subset = np.ones(M) * 0.5 # Array of 8 copies of 0.5\n",
    "        Q = Q_from_P(P_subset, S)\n",
    "\n",
    "        P0 = np.ones(M) * initial_prob\n",
    "        P_subset = estimate_P(X[G], mu, S, Descendants_and_self, draw=0, P0=P0, niter=niter, names=names_subset, clip=clip)\n",
    "        # Set draw = 0 to prevent drawing the graphs\n",
    "        \n",
    "        ### GENERATING PERMUTED DATA ###\n",
    "    \n",
    "        Ps = []\n",
    "        for n in range(nperm):\n",
    "            Xp = X[np.random.permutation(N)[G]]\n",
    "            P_ = estimate_P(Xp,mu,S,Descendants_and_self,draw=0,niter=niter,P0=P0)\n",
    "            Ps.append(P_)\n",
    "\n",
    "        Ps_sort = np.array([np.sort(Pi)[::-1] for Pi in Ps])\n",
    "        \n",
    "        ### PERMUTATION TESTING ###\n",
    "    \n",
    "        inds = np.argsort(P_subset)[::-1]\n",
    "        pval = np.zeros_like(P_subset)\n",
    "        alpha = 0.05\n",
    "        \n",
    "        pval_list = [] # Empty list to be filled\n",
    "        names_list = [] # Empty list to be filled\n",
    "        posterior_list = [] # Empty list to be filled\n",
    "        \n",
    "        for i in range(1):    \n",
    "            pval[inds[i]] = np.mean(Ps_sort[:,i] >= P_subset[inds[i]])\n",
    "            outputs.append(f\"{names_subset[inds[i]]}, P[Z=1|X]={P_subset[inds[i]]}, p={pval[inds[i]]}\")\n",
    "            # Every structure that gets rejected gets an entry\n",
    "            \n",
    "            pval_list.append(pval[inds[i]])\n",
    "            names_list.append(names_subset[inds[i]])\n",
    "            posterior_list.append(P_subset[inds[i]])\n",
    "        \n",
    "        ### SORT THE POSTERIOR VALUES ###\n",
    "        \n",
    "        # Use the subset adjacency matrix to create a dictionary\n",
    "        columns = np.array(subset.columns)\n",
    "        dictionary = dict(enumerate(columns.flatten(), 1))\n",
    "        dictionary = dict((value, key) for key, value in dictionary.items()) # Swap the keys and values\n",
    "        outputs = sorting_function(outputs, dictionary)\n",
    "        \n",
    "        ### SAVE DATA ### \n",
    "        \n",
    "        filename_new_this_repeat = basename + f'_repeat_{j:06d}' + extension\n",
    "        np.savez(filename_new_this_repeat, pval = pval_list, names = names_list, posterior = posterior_list, strings = outputs)\n",
    "        \n",
    "        ### OUTPUTS ###\n",
    "        return Ps_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7fef3715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCs for test 1:\u001b[0m\n",
      "[[3.31485862e-02 3.31485862e-02 3.31485862e-02 3.31485862e-02\n",
      "  7.77698973e-05 7.77698973e-05 6.90450538e-05 6.90450538e-05]\n",
      " [1.76153473e-01 1.76153473e-01 1.76153473e-01 1.76153473e-01\n",
      "  8.69987684e-02 8.69987684e-02 1.00338451e-03 1.00338451e-03]\n",
      " [4.53238447e-02 4.53238447e-02 4.53238447e-02 4.53238447e-02\n",
      "  1.71727766e-03 1.71727766e-03 5.83183538e-05 5.83183538e-05]\n",
      " [1.32299497e-01 1.32299497e-01 1.32299497e-01 1.32299497e-01\n",
      "  9.13059261e-02 9.13059261e-02 5.78283307e-05 5.78283307e-05]\n",
      " [3.46030816e-02 3.46030816e-02 3.46030816e-02 3.46030816e-02\n",
      "  1.21281973e-03 1.21281973e-03 4.40000426e-05 4.40000426e-05]\n",
      " [1.21444688e-01 1.21444688e-01 1.21444688e-01 1.21444688e-01\n",
      "  8.92345499e-02 8.92345499e-02 4.50403046e-05 4.50403046e-05]\n",
      " [1.26739395e-01 1.26739395e-01 1.26739395e-01 1.26739395e-01\n",
      "  8.77826605e-02 8.77826605e-02 5.74340612e-05 5.74340612e-05]\n",
      " [1.74058708e-01 1.74058708e-01 1.74058708e-01 1.74058708e-01\n",
      "  8.99656452e-02 8.99656452e-02 7.02593006e-04 7.02593006e-04]\n",
      " [2.26163172e-02 2.26163172e-02 2.26163172e-02 2.26163172e-02\n",
      "  6.28131300e-05 6.28131300e-05 4.25202116e-05 4.25202116e-05]\n",
      " [3.74611072e-02 3.74611072e-02 3.74611072e-02 3.74611072e-02\n",
      "  8.79432052e-04 8.79432052e-04 5.32628154e-05 5.32628154e-05]]\n",
      "\n",
      "\n",
      "\u001b[1mCs for test 2:\u001b[0m\n",
      "[[5.30766320e-01 5.30766320e-01 5.30766320e-01 5.30766320e-01\n",
      "  4.83510794e-01 4.83510794e-01 1.84688540e-04 1.84688540e-04]\n",
      " [5.12167014e-01 5.12167014e-01 5.12167014e-01 5.12167014e-01\n",
      "  4.89005428e-01 4.89005428e-01 3.98361307e-05 3.98361307e-05]\n",
      " [6.23709391e-01 6.23709391e-01 6.23709391e-01 6.23709391e-01\n",
      "  6.18197072e-01 6.18197072e-01 1.27523839e-04 1.27523839e-04]\n",
      " [3.52405047e-01 3.52405047e-01 3.52405047e-01 3.52405047e-01\n",
      "  3.20634405e-01 3.20634405e-01 4.51259765e-05 4.51259765e-05]\n",
      " [5.54472414e-01 5.54472414e-01 5.54472414e-01 5.54472414e-01\n",
      "  5.11746496e-01 5.11746496e-01 1.82152281e-04 1.82152281e-04]\n",
      " [5.30539812e-01 5.30539812e-01 5.30539812e-01 5.30539812e-01\n",
      "  4.68576327e-01 4.68576327e-01 8.65945321e-05 8.65945321e-05]\n",
      " [5.64431464e-01 5.64431464e-01 5.64431464e-01 5.64431464e-01\n",
      "  5.35926493e-01 5.35926493e-01 4.42280994e-05 4.42280994e-05]\n",
      " [4.00387571e-01 4.00387571e-01 4.00387571e-01 4.00387571e-01\n",
      "  3.68495595e-01 3.68495595e-01 4.26278354e-05 4.26278354e-05]\n",
      " [3.09739284e-01 3.09739284e-01 3.09739284e-01 3.09739284e-01\n",
      "  2.49949151e-01 2.49949151e-01 8.44873181e-05 8.44873181e-05]\n",
      " [6.00261401e-01 6.00261401e-01 6.00261401e-01 6.00261401e-01\n",
      "  5.93980137e-01 5.93980137e-01 1.33924727e-05 1.33924727e-05]]\n",
      "\n",
      "\n",
      "\u001b[1mCs for test 3:\u001b[0m\n",
      "[[0.60170965 0.60170965 0.60170965 0.60170965 0.52802492 0.52802492\n",
      "  0.43146438 0.43146438]\n",
      " [0.84881432 0.84881432 0.84881432 0.84881432 0.76078486 0.76078486\n",
      "  0.6449434  0.6449434 ]\n",
      " [0.66208812 0.66208812 0.66208812 0.66208812 0.64308233 0.64308233\n",
      "  0.55342969 0.55342969]\n",
      " [0.56935907 0.56935907 0.56935907 0.56935907 0.54987631 0.54987631\n",
      "  0.39020762 0.39020762]\n",
      " [0.57816529 0.57816529 0.57816529 0.57816529 0.53047676 0.53047676\n",
      "  0.39233897 0.39233897]\n",
      " [0.45552657 0.45552657 0.45552657 0.45552657 0.37895187 0.37895187\n",
      "  0.3485715  0.3485715 ]\n",
      " [0.58290149 0.58290149 0.58290149 0.58290149 0.49917464 0.49917464\n",
      "  0.38231276 0.38231276]\n",
      " [0.70695608 0.70695608 0.70695608 0.70695608 0.66715308 0.66715308\n",
      "  0.43816227 0.43816227]\n",
      " [0.58056267 0.58056267 0.58056267 0.58056267 0.55885546 0.55885546\n",
      "  0.49304565 0.49304565]\n",
      " [0.57427565 0.57427565 0.57427565 0.57427565 0.49629857 0.49629857\n",
      "  0.43310109 0.43310109]]\n",
      "\n",
      "\n",
      "\u001b[1mCs for test 4:\u001b[0m\n",
      "[[0.6957949  0.6957949  0.6957949  0.6957949  0.31939149 0.31939149\n",
      "  0.10783037 0.10783037]\n",
      " [0.66013338 0.66013338 0.66013338 0.66013338 0.30245786 0.30245786\n",
      "  0.05851953 0.05851953]\n",
      " [0.6980425  0.6980425  0.6980425  0.6980425  0.23679065 0.23679065\n",
      "  0.16276381 0.16276381]\n",
      " [0.64368808 0.64368808 0.64368808 0.64368808 0.23366594 0.23366594\n",
      "  0.12068303 0.12068303]\n",
      " [0.8027953  0.8027953  0.8027953  0.8027953  0.38224026 0.38224026\n",
      "  0.15033392 0.15033392]\n",
      " [0.87717451 0.87717451 0.87717451 0.87717451 0.27809156 0.27809156\n",
      "  0.25425221 0.25425221]\n",
      " [0.83878876 0.83878876 0.83878876 0.83878876 0.53133361 0.53133361\n",
      "  0.09997268 0.09997268]\n",
      " [0.66384264 0.66384264 0.66384264 0.66384264 0.18607544 0.18607544\n",
      "  0.17032787 0.17032787]\n",
      " [0.88425381 0.88425381 0.88425381 0.88425381 0.4978712  0.4978712\n",
      "  0.13762561 0.13762561]\n",
      " [0.89466742 0.89466742 0.89466742 0.89466742 0.35415683 0.35415683\n",
      "  0.25658072 0.25658072]]\n"
     ]
    }
   ],
   "source": [
    "# Permutation testing\n",
    "\n",
    "print(\"\\033[1m\" + \"Cs for test 1:\" + \"\\033[0m\")\n",
    "print(permutation_testing2(filename_old=\"test1_data_repeat_*\", filename_new = \"test1_results.npz\", subset=subset, n_repeats=10, nperm=10, N=20, mu=3.0, niter=5, initial_prob = 0.5, clip=0.001))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"\\033[1m\" + \"Cs for test 2:\" + \"\\033[0m\")\n",
    "print(permutation_testing2(filename_old=\"test2_data_repeat_*\", filename_new = \"test2_results.npz\", subset=subset, n_repeats=10, nperm=10, N=20, mu=3.0, niter=5, clip=0.0001, initial_prob = 0.5))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"\\033[1m\" + \"Cs for test 3:\" + \"\\033[0m\")\n",
    "print(permutation_testing2(filename_old=\"test3_data_repeat_*\", filename_new = \"test3_results.npz\", subset=subset, n_repeats=10, nperm=10, N=20, mu=3.0, niter=5, initial_prob = 0.25, clip=0.01))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"\\033[1m\" + \"Cs for test 4:\" + \"\\033[0m\")\n",
    "print(permutation_testing2(filename_old=\"test4_data_repeat_*\", filename_new = \"test4_results.npz\", subset=subset, n_repeats=10, nperm=10, N=20, mu=3.0, niter=5, initial_prob = 0.75, clip=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36d863d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
