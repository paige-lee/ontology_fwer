{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5ce0f91",
   "metadata": {},
   "source": [
    "## 1. Import libraries, load data, clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7ab59a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92620862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "\n",
    "adjacency_matrix = pd.read_csv(\"adjacency_matrix2.csv\", header=0, index_col=0)\n",
    "\n",
    "multilevel = pd.read_csv(\"multilevel2.csv\", header=0, index_col=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d445046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Everything</th>\n",
       "      <th>CSF_508_5</th>\n",
       "      <th>Myelencephalon_507_5</th>\n",
       "      <th>Metencephalon_506_5</th>\n",
       "      <th>Mesencephalon_505_5</th>\n",
       "      <th>Diencephalon_R_504_5</th>\n",
       "      <th>Diencephalon_L_503_5</th>\n",
       "      <th>Telencephalon_R_502_5</th>\n",
       "      <th>Telencephalon_L_501_5</th>\n",
       "      <th>Sulcus_R_500_4</th>\n",
       "      <th>...</th>\n",
       "      <th>MFG_DPFC_R_10_1</th>\n",
       "      <th>MFG_DPFC_L_9_1</th>\n",
       "      <th>MFG_R_8_1</th>\n",
       "      <th>MFG_L_7_1</th>\n",
       "      <th>SFG_pole_R_6_1</th>\n",
       "      <th>SFG_pole_L_5_1</th>\n",
       "      <th>SFG_PFC_R_4_1</th>\n",
       "      <th>SFG_PFC_L_3_1</th>\n",
       "      <th>SFG_R_2_1</th>\n",
       "      <th>SFG_L_1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Everything</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSF_508_5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Myelencephalon_507_5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metencephalon_506_5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mesencephalon_505_5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SFG_pole_L_5_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SFG_PFC_R_4_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SFG_PFC_L_3_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SFG_R_2_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SFG_L_1_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>509 rows × 509 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Everything  CSF_508_5  Myelencephalon_507_5  \\\n",
       "Everything                     0          1                     1   \n",
       "CSF_508_5                      0          0                     0   \n",
       "Myelencephalon_507_5           0          0                     0   \n",
       "Metencephalon_506_5            0          0                     0   \n",
       "Mesencephalon_505_5            0          0                     0   \n",
       "...                          ...        ...                   ...   \n",
       "SFG_pole_L_5_1                 0          0                     0   \n",
       "SFG_PFC_R_4_1                  0          0                     0   \n",
       "SFG_PFC_L_3_1                  0          0                     0   \n",
       "SFG_R_2_1                      0          0                     0   \n",
       "SFG_L_1_1                      0          0                     0   \n",
       "\n",
       "                      Metencephalon_506_5  Mesencephalon_505_5  \\\n",
       "Everything                              1                    1   \n",
       "CSF_508_5                               0                    0   \n",
       "Myelencephalon_507_5                    0                    0   \n",
       "Metencephalon_506_5                     0                    0   \n",
       "Mesencephalon_505_5                     0                    0   \n",
       "...                                   ...                  ...   \n",
       "SFG_pole_L_5_1                          0                    0   \n",
       "SFG_PFC_R_4_1                           0                    0   \n",
       "SFG_PFC_L_3_1                           0                    0   \n",
       "SFG_R_2_1                               0                    0   \n",
       "SFG_L_1_1                               0                    0   \n",
       "\n",
       "                      Diencephalon_R_504_5  Diencephalon_L_503_5  \\\n",
       "Everything                               1                     1   \n",
       "CSF_508_5                                0                     0   \n",
       "Myelencephalon_507_5                     0                     0   \n",
       "Metencephalon_506_5                      0                     0   \n",
       "Mesencephalon_505_5                      0                     0   \n",
       "...                                    ...                   ...   \n",
       "SFG_pole_L_5_1                           0                     0   \n",
       "SFG_PFC_R_4_1                            0                     0   \n",
       "SFG_PFC_L_3_1                            0                     0   \n",
       "SFG_R_2_1                                0                     0   \n",
       "SFG_L_1_1                                0                     0   \n",
       "\n",
       "                      Telencephalon_R_502_5  Telencephalon_L_501_5  \\\n",
       "Everything                                1                      1   \n",
       "CSF_508_5                                 0                      0   \n",
       "Myelencephalon_507_5                      0                      0   \n",
       "Metencephalon_506_5                       0                      0   \n",
       "Mesencephalon_505_5                       0                      0   \n",
       "...                                     ...                    ...   \n",
       "SFG_pole_L_5_1                            0                      0   \n",
       "SFG_PFC_R_4_1                             0                      0   \n",
       "SFG_PFC_L_3_1                             0                      0   \n",
       "SFG_R_2_1                                 0                      0   \n",
       "SFG_L_1_1                                 0                      0   \n",
       "\n",
       "                      Sulcus_R_500_4  ...  MFG_DPFC_R_10_1  MFG_DPFC_L_9_1  \\\n",
       "Everything                         0  ...                0               0   \n",
       "CSF_508_5                          1  ...                0               0   \n",
       "Myelencephalon_507_5               0  ...                0               0   \n",
       "Metencephalon_506_5                0  ...                0               0   \n",
       "Mesencephalon_505_5                0  ...                0               0   \n",
       "...                              ...  ...              ...             ...   \n",
       "SFG_pole_L_5_1                     0  ...                0               0   \n",
       "SFG_PFC_R_4_1                      0  ...                0               0   \n",
       "SFG_PFC_L_3_1                      0  ...                0               0   \n",
       "SFG_R_2_1                          0  ...                0               0   \n",
       "SFG_L_1_1                          0  ...                0               0   \n",
       "\n",
       "                      MFG_R_8_1  MFG_L_7_1  SFG_pole_R_6_1  SFG_pole_L_5_1  \\\n",
       "Everything                    0          0               0               0   \n",
       "CSF_508_5                     0          0               0               0   \n",
       "Myelencephalon_507_5          0          0               0               0   \n",
       "Metencephalon_506_5           0          0               0               0   \n",
       "Mesencephalon_505_5           0          0               0               0   \n",
       "...                         ...        ...             ...             ...   \n",
       "SFG_pole_L_5_1                0          0               0               0   \n",
       "SFG_PFC_R_4_1                 0          0               0               0   \n",
       "SFG_PFC_L_3_1                 0          0               0               0   \n",
       "SFG_R_2_1                     0          0               0               0   \n",
       "SFG_L_1_1                     0          0               0               0   \n",
       "\n",
       "                      SFG_PFC_R_4_1  SFG_PFC_L_3_1  SFG_R_2_1  SFG_L_1_1  \n",
       "Everything                        0              0          0          0  \n",
       "CSF_508_5                         0              0          0          0  \n",
       "Myelencephalon_507_5              0              0          0          0  \n",
       "Metencephalon_506_5               0              0          0          0  \n",
       "Mesencephalon_505_5               0              0          0          0  \n",
       "...                             ...            ...        ...        ...  \n",
       "SFG_pole_L_5_1                    0              0          0          0  \n",
       "SFG_PFC_R_4_1                     0              0          0          0  \n",
       "SFG_PFC_L_3_1                     0              0          0          0  \n",
       "SFG_R_2_1                         0              0          0          0  \n",
       "SFG_L_1_1                         0              0          0          0  \n",
       "\n",
       "[509 rows x 509 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the adjacency matrix\n",
    "\n",
    "def clean_adjacency_mat(adjacency_matrix):\n",
    "    # Reverse the order of columns \n",
    "    columns = adjacency_matrix.columns.tolist()\n",
    "    columns = columns[::-1]\n",
    "    adjacency_matrix = adjacency_matrix[columns]\n",
    "    \n",
    "    # Reverse the order of rows\n",
    "    adjacency_matrix = adjacency_matrix[::-1]\n",
    "    \n",
    "    # Take the transpose of the matrix\n",
    "    adjacency_matrix = adjacency_matrix.T\n",
    "    \n",
    "    return adjacency_matrix\n",
    "\n",
    "adjacency_matrix = clean_adjacency_mat(adjacency_matrix)\n",
    "adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f39f22d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Structure</th>\n",
       "      <th>Immediate.parent</th>\n",
       "      <th>Immediate.child.children</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>1</td>\n",
       "      <td>Everything</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Telencephalon_L_501_5, Telencephalon_R_502_5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>2</td>\n",
       "      <td>CSF_508_5</td>\n",
       "      <td>Everything</td>\n",
       "      <td>Ventricle_498_4, Sulcus_L_499_4, Sulcus_R_500_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>3</td>\n",
       "      <td>Myelencephalon_507_5</td>\n",
       "      <td>Everything</td>\n",
       "      <td>Myelencephalon_L_494_4, Myelencephalon_R_495_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>4</td>\n",
       "      <td>Metencephalon_506_5</td>\n",
       "      <td>Everything</td>\n",
       "      <td>Metencephalon_L_492_4, Metencephalon_R_493_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>5</td>\n",
       "      <td>Mesencephalon_505_5</td>\n",
       "      <td>Everything</td>\n",
       "      <td>Mesencephalon_L_490_4, Mesencephalon_R_491_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>505</td>\n",
       "      <td>SFG_pole_L_5_1</td>\n",
       "      <td>SFG_L_290_2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>506</td>\n",
       "      <td>SFG_PFC_R_4_1</td>\n",
       "      <td>SFG_R_291_2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>507</td>\n",
       "      <td>SFG_PFC_L_3_1</td>\n",
       "      <td>SFG_L_290_2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>508</td>\n",
       "      <td>SFG_R_2_1</td>\n",
       "      <td>SFG_R_291_2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>509</td>\n",
       "      <td>SFG_L_1_1</td>\n",
       "      <td>SFG_L_290_2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>509 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Number             Structure Immediate.parent  \\\n",
       "509       1            Everything              NaN   \n",
       "508       2             CSF_508_5       Everything   \n",
       "507       3  Myelencephalon_507_5       Everything   \n",
       "506       4   Metencephalon_506_5       Everything   \n",
       "505       5   Mesencephalon_505_5       Everything   \n",
       "..      ...                   ...              ...   \n",
       "5       505        SFG_pole_L_5_1      SFG_L_290_2   \n",
       "4       506         SFG_PFC_R_4_1      SFG_R_291_2   \n",
       "3       507         SFG_PFC_L_3_1      SFG_L_290_2   \n",
       "2       508             SFG_R_2_1      SFG_R_291_2   \n",
       "1       509             SFG_L_1_1      SFG_L_290_2   \n",
       "\n",
       "                              Immediate.child.children  \n",
       "509  Telencephalon_L_501_5, Telencephalon_R_502_5, ...  \n",
       "508    Ventricle_498_4, Sulcus_L_499_4, Sulcus_R_500_4  \n",
       "507     Myelencephalon_L_494_4, Myelencephalon_R_495_4  \n",
       "506       Metencephalon_L_492_4, Metencephalon_R_493_4  \n",
       "505       Mesencephalon_L_490_4, Mesencephalon_R_491_4  \n",
       "..                                                 ...  \n",
       "5                                                  NaN  \n",
       "4                                                  NaN  \n",
       "3                                                  NaN  \n",
       "2                                                  NaN  \n",
       "1                                                  NaN  \n",
       "\n",
       "[509 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the multilevel lookup table\n",
    "\n",
    "def clean_multilevel(multilevel):\n",
    "    # Reverse the order of rows\n",
    "    multilevel = multilevel[::-1]\n",
    "    \n",
    "    # Reassign the numbers\n",
    "    multilevel.Number = range(1, adjacency_matrix.shape[0] + 1) \n",
    "    \n",
    "    return multilevel\n",
    "\n",
    "multilevel = clean_multilevel(multilevel)\n",
    "multilevel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b555c10",
   "metadata": {},
   "source": [
    "## 2. Create a subset of the adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e0002d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Everything</th>\n",
       "      <th>Telencephalon_L_501_5</th>\n",
       "      <th>CerebralCortex_L_482_4</th>\n",
       "      <th>Limbic_L_434_3</th>\n",
       "      <th>Hippo_L_338_2</th>\n",
       "      <th>Amyg_L_336_2</th>\n",
       "      <th>Hippo_L_75_1</th>\n",
       "      <th>Amyg_L_73_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Everything</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Telencephalon_L_501_5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CerebralCortex_L_482_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Limbic_L_434_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hippo_L_338_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amyg_L_336_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hippo_L_75_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amyg_L_73_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Everything  Telencephalon_L_501_5  \\\n",
       "Everything                       0                      1   \n",
       "Telencephalon_L_501_5            0                      0   \n",
       "CerebralCortex_L_482_4           0                      0   \n",
       "Limbic_L_434_3                   0                      0   \n",
       "Hippo_L_338_2                    0                      0   \n",
       "Amyg_L_336_2                     0                      0   \n",
       "Hippo_L_75_1                     0                      0   \n",
       "Amyg_L_73_1                      0                      0   \n",
       "\n",
       "                        CerebralCortex_L_482_4  Limbic_L_434_3  Hippo_L_338_2  \\\n",
       "Everything                                   0               0              0   \n",
       "Telencephalon_L_501_5                        1               0              0   \n",
       "CerebralCortex_L_482_4                       0               1              0   \n",
       "Limbic_L_434_3                               0               0              1   \n",
       "Hippo_L_338_2                                0               0              0   \n",
       "Amyg_L_336_2                                 0               0              0   \n",
       "Hippo_L_75_1                                 0               0              0   \n",
       "Amyg_L_73_1                                  0               0              0   \n",
       "\n",
       "                        Amyg_L_336_2  Hippo_L_75_1  Amyg_L_73_1  \n",
       "Everything                         0             0            0  \n",
       "Telencephalon_L_501_5              0             0            0  \n",
       "CerebralCortex_L_482_4             0             0            0  \n",
       "Limbic_L_434_3                     1             0            0  \n",
       "Hippo_L_338_2                      0             1            0  \n",
       "Amyg_L_336_2                       0             0            1  \n",
       "Hippo_L_75_1                       0             0            0  \n",
       "Amyg_L_73_1                        0             0            0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def subset_matrix_creator(subset_leaf_list):\n",
    "    full_subset_list = subset_leaf_list # This list will get filled\n",
    "    iterations = 5 * len(subset_leaf_list) - 1\n",
    "    \n",
    "    for i in range(0, len(subset_leaf_list)): # For each leaf structure\n",
    "        for j in range(0, iterations): # Iterate over the 4 other levels in this ontology (5 levels * number of leaves)\n",
    "\n",
    "            # Structure index\n",
    "            structure_index = int(np.where(multilevel[\"Structure\"] == full_subset_list[j])[0])\n",
    "            structure_index = (adjacency_matrix.shape[0]) - structure_index\n",
    "            structure = multilevel[\"Structure\"][structure_index]\n",
    "\n",
    "            full_subset_list.append(multilevel[\"Immediate.parent\"][structure_index])\n",
    "        \n",
    "    full_subset_list = set(full_subset_list)\n",
    "    full_subset_list = pd.DataFrame(full_subset_list)\n",
    "        \n",
    "    pattern = r\"_[0-9]+_\"\n",
    "    structure_numbers = []\n",
    "    \n",
    "    for i in range(0, full_subset_list.shape[0]):\n",
    "        if full_subset_list[0][i] == \"Everything\":\n",
    "            structure_numbers.append(float(\"inf\")) # Assign the number \"inf\" to \"Everything\" for flexibility\n",
    "        else:\n",
    "            number = re.findall(pattern, full_subset_list[0][i])[0]\n",
    "            number = re.sub(\"[^0-9]\", \"\", number)\n",
    "            number = int(number)\n",
    "            structure_numbers.append(number)\n",
    "    \n",
    "    full_subset_list[\"structure_numbers\"] = structure_numbers\n",
    "    full_subset_list = full_subset_list.sort_values(by = [\"structure_numbers\"], axis = 0)\n",
    "    full_subset_list = full_subset_list[0].tolist()\n",
    "    \n",
    "    # Index the rows and columns of the adjacency matrix by these structures to create a subset\n",
    "    subset = adjacency_matrix[full_subset_list]\n",
    "    subset = subset.loc[full_subset_list]\n",
    "\n",
    "    # Reverse the order of rows and columns in the subset of the adjacency matrix\n",
    "    cols = subset.columns.tolist()\n",
    "    cols = cols[::-1]\n",
    "    subset = subset[cols]\n",
    "    subset = subset[::-1]\n",
    "    \n",
    "    return subset\n",
    "\n",
    "\n",
    "# User inputs a list of leaf structures\n",
    "subset_leaf_list = [\"Amyg_L_73_1\", \"Hippo_L_75_1\"]\n",
    "\n",
    "subset = subset_matrix_creator(subset_leaf_list)\n",
    "subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a606ec92",
   "metadata": {},
   "source": [
    "## 3. Creating adjacency matrices of descendants and ancestors for the subset\n",
    "\n",
    "Note: the `adjacency_descendants()` function is designed only for a 5-level ontology since it contains a certain line of code that is repeated 5 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37323103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [False, False,  True,  True,  True,  True,  True,  True],\n",
       "       [False, False, False,  True,  True,  True,  True,  True],\n",
       "       [False, False, False, False,  True,  True,  True,  True],\n",
       "       [False, False, False, False, False, False,  True, False],\n",
       "       [False, False, False, False, False, False, False,  True],\n",
       "       [False, False, False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an adjacency matrix of descendants\n",
    "\n",
    "# N is the number of samples\n",
    "# mu is the difference in mean, note that this is generally unknown\n",
    "# M is the number of total unique structures\n",
    "\n",
    "def adjacency_descendants(adjacency_matrix, N, mu):\n",
    "    M = adjacency_matrix.shape[0]\n",
    "    names_full = adjacency_matrix.columns # List of the 509 structures' names\n",
    "    A = np.array(adjacency_matrix, dtype = bool)\n",
    "    Descendants = np.copy(A)\n",
    "    \n",
    "    Descendants = np.logical_or(Descendants,Descendants@A)\n",
    "    Descendants = np.logical_or(Descendants,Descendants@A)\n",
    "    Descendants = np.logical_or(Descendants,Descendants@A)\n",
    "    Descendants = np.logical_or(Descendants,Descendants@A)\n",
    "    Descendants = np.logical_or(Descendants,Descendants@A)\n",
    "    Descendants = np.logical_or(Descendants,Descendants@A)\n",
    "    \n",
    "    return Descendants\n",
    "\n",
    "descendants = adjacency_descendants(subset, N=20, mu=3.0)\n",
    "descendants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62a74d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False, False, False, False, False],\n",
       "       [ True, False, False, False, False, False, False, False],\n",
       "       [ True,  True, False, False, False, False, False, False],\n",
       "       [ True,  True,  True, False, False, False, False, False],\n",
       "       [ True,  True,  True,  True, False, False, False, False],\n",
       "       [ True,  True,  True,  True, False, False, False, False],\n",
       "       [ True,  True,  True,  True,  True, False, False, False],\n",
       "       [ True,  True,  True,  True, False,  True, False, False]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an adjacency matrix of ancestors\n",
    "\n",
    "# N is the number of samples\n",
    "# mu is the difference in mean, note that this is generally unknown\n",
    "# M is the number of total unique structures\n",
    "\n",
    "def adjacency_ancestors(adjacency_matrix, N, mu):\n",
    "    M = adjacency_matrix.shape[0]\n",
    "    Descendants = adjacency_descendants(adjacency_matrix, N, mu)\n",
    "    Ancestors = Descendants.T # Take transpose of descendants matrix to get ancestors    \n",
    "    Ancestors_and_self = np.logical_or(Ancestors,np.eye(M))\n",
    "    \n",
    "    return Ancestors\n",
    "\n",
    "ancestors = adjacency_ancestors(subset, N=20, mu=3.0)\n",
    "ancestors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e247c0e1",
   "metadata": {},
   "source": [
    "## 4. Professor Tward's functions for parameter estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a320a320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function for phi (CDF of the standard normal distribution)\n",
    "def phi(x,mu=0.0):\n",
    "    '''Gaussian'''\n",
    "    return 1.0/np.sqrt(2.0*np.pi)*np.exp(-(x - mu)**2/2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c68efe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function for calculating P (probabilities of Z) from Q (conditional probability of Z given parent)\n",
    "def P_from_Q(Q,Ancestors_and_self):\n",
    "    '''I don't need this function\n",
    "    '''\n",
    "    P = np.empty_like(Q)\n",
    "    for i in range(M):\n",
    "        P[i] = np.prod(Q[Ancestors_and_self[i,:]])\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "200ecf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function for calculating Q (conditional probability of Z given parent) from P (probabilities of Z)\n",
    "def Q_from_P(P,A):\n",
    "    M = A.shape[0]\n",
    "    # now we need to calculate Q\n",
    "    Q = np.zeros_like(P)\n",
    "    Q[0] = P[0]\n",
    "    for i in range(1,M):\n",
    "        Q[i] = P[i] / P[A[:,i]]\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba23da35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function for estimating P\n",
    "def estimate_P(X, mu, A, Descendants_and_self, draw=False, niter=100, P0=None, names=None, clip=0.001):\n",
    "\n",
    "    if draw: \n",
    "        f,ax = plt.subplots(2,2)\n",
    "        if names is None:\n",
    "            names = np.arange(A.shape[0])\n",
    "\n",
    "    N = X.shape[0]\n",
    "    m = X.shape[1]\n",
    "    M = A.shape[0]\n",
    "    is_leaf = np.sum(descendants_and_self, 1) == 1\n",
    "    \n",
    "    # okay now comes my algorithm\n",
    "    # initialize\n",
    "    if P0 is None:\n",
    "        P = np.ones(M)*0.5\n",
    "    else:\n",
    "        P = np.asarray(P0)\n",
    "    \n",
    "    for it in range(niter):\n",
    "        # calculate leaf posterior (this is prob of no effect)\n",
    "        #leaf_posterior = ((1.0-P[is_leaf])*phi(X))\n",
    "        #leaf_posterior = leaf_posterior/(leaf_posterior + P[is_leaf]*phi(X,mu) )\n",
    "        P_ = np.maximum(P, clip) # Clip probability: if P is very small, then set it to 0.001\n",
    "        P_ = np.minimum(P_, 1-clip) # Clip probability: if P_ is very big, then set it to 0.999\n",
    "        P_over_one_minus_P = P_/(1.0-P_)\n",
    "        #leaf_log_posterior = -np.log(1.0 + P_over_one_minus_P[is_leaf]*phi(X,mu)/phi(X) )\n",
    "        leaf_log_posterior = -np.log1p( P_over_one_minus_P[is_leaf]*phi(X,mu)/phi(X) )\n",
    "        \n",
    "\n",
    "        # calculate posterior for all structures\n",
    "        # now for each structure, I need a leaf likelihod, and an adjustment\n",
    "        #posterior = np.zeros((N,M))\n",
    "        log_posterior = np.zeros((N,M))\n",
    "        for i in range(M):\n",
    "            #posterior[:,i] = np.prod(leaf_posterior[:,Descendants_and_self[i,:][is_leaf]],1)\n",
    "            log_posterior[:,i] = np.sum(leaf_log_posterior[:,Descendants_and_self[i,:][is_leaf]],1)\n",
    "        \n",
    "        # calculate adjustment factor for correlations\n",
    "        Q = Q_from_P(P,A)\n",
    "        #adjustment_single = np.ones(M)\n",
    "        log_adjustment_single = np.zeros(M)\n",
    "        for i in range(M):\n",
    "            if is_leaf[i]:\n",
    "                continue\n",
    "            #adjustment_single[i] = (1.0 - P[i])/ ((1.0 - P[i]) + P[i]*np.prod(1.0 - Q[A[i,:]]))\n",
    "            #log_adjustment_single[i] = -np.log(1.0 + P_over_one_minus_P[i]*np.prod(1.0 - Q[A[i,:]]))\n",
    "            log_adjustment_single[i] = -np.log1p(P_over_one_minus_P[i]*np.prod(1.0 - Q[A[i,:]]))\n",
    "            \n",
    "        \n",
    "        # now my adjust ment requres products of all descendants\n",
    "        #adjustment = np.ones(M)\n",
    "        log_adjustment = np.ones(M)\n",
    "        for i in range(M):\n",
    "            #adjustment[i] = np.prod(adjustment_single[Descendants_and_self[i,:]])\n",
    "            log_adjustment[i] = np.sum(log_adjustment_single[Descendants_and_self[i,:]])\n",
    "            \n",
    "\n",
    "        # calculate the adjusted posterior\n",
    "        #posterior = posterior*adjustment\n",
    "        log_posterior = log_posterior + log_adjustment\n",
    "        \n",
    "        #P = np.sum(1.0 - posterior,0)/N        \n",
    "        #P = np.sum(1.0 - np.exp(log_posterior),0)/N\n",
    "        P = -np.sum(np.expm1(log_posterior),0)/N\n",
    "        posterior = np.exp(log_posterior)\n",
    "        \n",
    "        # draw        \n",
    "        if draw>0 and ( (not it%draw) or (it==niter-1)):     \n",
    "            \n",
    "            ax[0,0].cla()\n",
    "            ax[0,0].imshow(posterior, vmin = 0, vmax = 1)\n",
    "            ax[0,0].set_aspect('auto')\n",
    "            ax[0,0].set_title('P[Z=0|X] (prob not affected)')\n",
    "            ax[0,0].set_xticks(np.arange(M))\n",
    "            ax[0,0].set_xticklabels(names,rotation=15, fontsize = 5)\n",
    "            ax[0,0].set_ylabel('Sample')\n",
    "\n",
    "            ax[0,1].cla()\n",
    "            ax[0,1].bar(np.arange(M),P)\n",
    "            ax[0,1].set_xticks(np.arange(M))\n",
    "            ax[0,1].set_xticklabels(names,rotation=15, fontsize = 5)\n",
    "            ax[0,1].set_ylim((0, 1))\n",
    "\n",
    "            f.canvas.draw()\n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcdbd08",
   "metadata": {},
   "source": [
    "## 5. Generate samples, parameter estimation, permutation testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c8af947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_testing(filename, subset, case, n_repeats, nperm, N, mu, niter, clip, initial_prob):\n",
    "    M = subset.shape[0] # Number of total unique structures\n",
    "    S = np.array(subset, dtype = bool)\n",
    "    names_subset = subset.columns # List of the 8 structures' names\n",
    "    Descendants = adjacency_descendants(subset, N=N, mu=mu)\n",
    "    Descendants_and_self = np.logical_or(Descendants, np.eye(M))\n",
    "    \n",
    "    for j in range(n_repeats):\n",
    "        outputs = [] # Empty list for each iteration\n",
    "        Z = np.zeros((N,M)) # Initialize Z, which will be a binary variable that tells us if a structure is affected\n",
    "        Naffected = N // 2 # Don't set Naffected to 0 or else there won't be any samples\n",
    "        number_of_leaves = np.count_nonzero(np.sum(subset, 1) == 0) # Number of leaf structures (zero children)\n",
    "        \n",
    "        ### GENERATING SAMPLES ### \n",
    "        \n",
    "        if case == 1:\n",
    "            pass\n",
    "        elif case == 2:\n",
    "            for i in range(N):\n",
    "                if i < Naffected: # Assume that the first half of samples are affected and second half are not\n",
    "                    Z[i][6] = 1 # Left hippocampus is affected\n",
    "        elif case == 3:\n",
    "            for i in range(N):\n",
    "                if i < Naffected: # Assume that the first half of samples are affected and second half are not\n",
    "                    Z[i][6] = 1 # Left hippocampus is affected\n",
    "                    Z[i][7] = 1 # Left amygdala is affected\n",
    "        elif case == 4:\n",
    "            for i in range(N):\n",
    "                if i < Naffected: # Assume that the first half of samples are affected and second half are not\n",
    "                    if np.random.rand() < 0.5:\n",
    "                        Z[i][6] = 1 # Left hippocampus is affected\n",
    "                    else:\n",
    "                        Z[i][7] = 1 # Left amygdala is affected\n",
    "        \n",
    "            \n",
    "        is_leaf = np.concatenate([np.ones(number_of_leaves), np.zeros(M - number_of_leaves)]) # 1 for leaf structures, 0 for non-leaf structures\n",
    "        is_leaf = np.array(is_leaf, dtype = bool) # Convert is_leaf to the boolean type\n",
    "        is_leaf = is_leaf[::-1] # Data specific\n",
    "        m = np.sum(is_leaf) # Number of leaf structures (m = 2)\n",
    "            \n",
    "        G = np.arange(N) < Naffected # All falses since all samples are unaffected\n",
    "        X = Z[:, is_leaf > 0] * mu + np.random.randn(N, m)\n",
    "        \n",
    "        ### PARAMETER ESTIMATION ###\n",
    "    \n",
    "        P_subset = np.ones(M) * 0.5 # Array of 8 copies of 0.5\n",
    "        Q = Q_from_P(P_subset, S)\n",
    "\n",
    "        P0 = np.ones(M) * initial_prob\n",
    "        P_subset = estimate_P(X[G], mu, S, Descendants_and_self, draw=0, P0=P0, niter=niter, names=names_subset, clip=clip)\n",
    "        # Set draw = 0 to prevent drawing the graphs\n",
    "        \n",
    "        ### GENERATING PERMUTED DATA ###\n",
    "    \n",
    "        Ps = []\n",
    "        for n in range(nperm):\n",
    "            Xp = X[np.random.permutation(N)[G]]\n",
    "            P_ = estimate_P(Xp,mu,S,Descendants_and_self,draw=0,niter=niter,P0=P0)\n",
    "            Ps.append(P_)\n",
    "\n",
    "        Ps_sort = np.array([np.sort(Pi)[::-1] for Pi in Ps])\n",
    "        \n",
    "        ### PERMUTATION TESTING ###\n",
    "    \n",
    "        inds = np.argsort(P_subset)[::-1]\n",
    "        pval = np.zeros_like(P_subset)\n",
    "        alpha = 0.05\n",
    "        \n",
    "        pval_list = [] # Empty list to be filled\n",
    "        names_list = [] # Empty list to be filled\n",
    "        posterior_list = [] # Empty list to be filled\n",
    "        \n",
    "        for i in range(M):    \n",
    "            pval[inds[i]] = np.mean(Ps_sort[:,i] >= P_subset[inds[i]])\n",
    "            outputs.append(f\"{names_subset[inds[i]]}, P[Z=1|X]={P_subset[inds[i]]}, p={pval[inds[i]]}\")\n",
    "            # Every structure that gets rejected gets an entry\n",
    "            \n",
    "            pval_list.append(pval[inds[i]])\n",
    "            names_list.append(names_subset[inds[i]])\n",
    "            posterior_list.append(P_subset[inds[i]])\n",
    "        \n",
    "        ### SAVE DATA ### \n",
    "        \n",
    "        np.savez(filename, pval = pval_list, names = names_list, posterior = posterior_list, strings = outputs)\n",
    "    \n",
    "\n",
    "    \n",
    "permutation_testing(filename=\"test1\", subset=subset, case=1, n_repeats=10, nperm=10, N=20, mu=3.0, niter=5, initial_prob = 0.5, clip=0.001)\n",
    "permutation_testing(filename=\"test2\", subset=subset, case=2, n_repeats=10, nperm=10, N=20, mu=3.0, niter=5, clip=0.0001, initial_prob = 0.5)\n",
    "permutation_testing(filename=\"test3\", subset=subset, case=3, n_repeats=10, nperm=10, N=20, mu=3.0, niter=5, initial_prob = 0.25, clip=0.01)\n",
    "permutation_testing(filename=\"test4\", subset=subset, case=4, n_repeats=10, nperm=10, N=20, mu=3.0, niter=5, initial_prob = 0.75, clip=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "57911783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mtest1.npz\u001b[0m\n",
      "\u001b[1mp-values:\u001b[0m\n",
      "[0.3 0.3 0.3 0.3 0.8 0.8 0.1 0.1]\n",
      "\u001b[1mnames:\u001b[0m\n",
      "['Limbic_L_434_3' 'CerebralCortex_L_482_4' 'Telencephalon_L_501_5'\n",
      " 'Everything' 'Hippo_L_75_1' 'Hippo_L_338_2' 'Amyg_L_73_1' 'Amyg_L_336_2']\n",
      "\u001b[1mposterior:\u001b[0m\n",
      "[1.60620364e-02 1.60620364e-02 1.60620364e-02 1.60620364e-02\n",
      " 5.23390939e-05 5.23390939e-05 2.57519570e-05 2.57519570e-05]\n",
      "\u001b[1mstrings:\u001b[0m\n",
      "['Limbic_L_434_3, P[Z=1|X]=0.016062036380104783, p=0.3'\n",
      " 'CerebralCortex_L_482_4, P[Z=1|X]=0.016062036380104783, p=0.3'\n",
      " 'Telencephalon_L_501_5, P[Z=1|X]=0.016062036380104783, p=0.3'\n",
      " 'Everything, P[Z=1|X]=0.016062036380104783, p=0.3'\n",
      " 'Hippo_L_75_1, P[Z=1|X]=5.233909387907838e-05, p=0.8'\n",
      " 'Hippo_L_338_2, P[Z=1|X]=5.233909387907838e-05, p=0.8'\n",
      " 'Amyg_L_73_1, P[Z=1|X]=2.5751956950708733e-05, p=0.1'\n",
      " 'Amyg_L_336_2, P[Z=1|X]=2.5751956950708733e-05, p=0.1']\n",
      "\u001b[1mtest2.npz\u001b[0m\n",
      "\u001b[1mp-values:\u001b[0m\n",
      "[0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "\u001b[1mnames:\u001b[0m\n",
      "['Limbic_L_434_3' 'CerebralCortex_L_482_4' 'Telencephalon_L_501_5'\n",
      " 'Everything' 'Hippo_L_75_1' 'Hippo_L_338_2' 'Amyg_L_73_1' 'Amyg_L_336_2']\n",
      "\u001b[1mposterior:\u001b[0m\n",
      "[9.99998102e-01 9.99998102e-01 9.99998102e-01 9.99998102e-01\n",
      " 9.99998102e-01 9.99998102e-01 4.13539887e-06 4.13539887e-06]\n",
      "\u001b[1mstrings:\u001b[0m\n",
      "['Limbic_L_434_3, P[Z=1|X]=0.9999981018619202, p=0.0'\n",
      " 'CerebralCortex_L_482_4, P[Z=1|X]=0.9999981018619202, p=0.0'\n",
      " 'Telencephalon_L_501_5, P[Z=1|X]=0.9999981018619202, p=0.0'\n",
      " 'Everything, P[Z=1|X]=0.9999981018619202, p=0.0'\n",
      " 'Hippo_L_75_1, P[Z=1|X]=0.9999981017988212, p=0.0'\n",
      " 'Hippo_L_338_2, P[Z=1|X]=0.9999981017988212, p=0.0'\n",
      " 'Amyg_L_73_1, P[Z=1|X]=4.135398865672112e-06, p=1.0'\n",
      " 'Amyg_L_336_2, P[Z=1|X]=4.135398865672112e-06, p=1.0']\n",
      "\u001b[1mtest3.npz\u001b[0m\n",
      "\u001b[1mp-values:\u001b[0m\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\u001b[1mnames:\u001b[0m\n",
      "['Limbic_L_434_3' 'CerebralCortex_L_482_4' 'Telencephalon_L_501_5'\n",
      " 'Everything' 'Hippo_L_75_1' 'Hippo_L_338_2' 'Amyg_L_73_1' 'Amyg_L_336_2']\n",
      "\u001b[1mposterior:\u001b[0m\n",
      "[0.99999552 0.99999552 0.99999552 0.99999552 0.99953602 0.99953602\n",
      " 0.93678614 0.93678614]\n",
      "\u001b[1mstrings:\u001b[0m\n",
      "['Limbic_L_434_3, P[Z=1|X]=0.9999955228342035, p=0.0'\n",
      " 'CerebralCortex_L_482_4, P[Z=1|X]=0.9999955228342035, p=0.0'\n",
      " 'Telencephalon_L_501_5, P[Z=1|X]=0.9999955228342035, p=0.0'\n",
      " 'Everything, P[Z=1|X]=0.9999955228342035, p=0.0'\n",
      " 'Hippo_L_75_1, P[Z=1|X]=0.9995360155499929, p=0.0'\n",
      " 'Hippo_L_338_2, P[Z=1|X]=0.9995360155499929, p=0.0'\n",
      " 'Amyg_L_73_1, P[Z=1|X]=0.9367861424216901, p=0.0'\n",
      " 'Amyg_L_336_2, P[Z=1|X]=0.9367861424216901, p=0.0']\n"
     ]
    }
   ],
   "source": [
    "# Viewing the contents of the .npz files to check\n",
    "# Using \"\\033[1m\" and \"\\033[0m\" to get bold text printed\n",
    "\n",
    "filename = [\"test1.npz\", \"test2.npz\", \"test3.npz\", \"test4.npz\"]\n",
    "for i in range(0, 3):\n",
    "    # Assign the file to an object called \"test,\" which is a dictionary object\n",
    "    test = np.load(filename[i])\n",
    "    print(\"\\033[1m\" + filename[i] + \"\\033[0m\") \n",
    "\n",
    "    # Print the values corresponding to each key\n",
    "    print(\"\\033[1m\" + \"p-values:\" + \"\\033[0m\")\n",
    "    print(test[\"pval\"])\n",
    "    \n",
    "    print(\"\\033[1m\" + \"names:\" + \"\\033[0m\")\n",
    "    print(test[\"names\"])\n",
    "    \n",
    "    print(\"\\033[1m\" + \"posterior:\" + \"\\033[0m\")\n",
    "    print(test[\"posterior\"])\n",
    "    \n",
    "    print(\"\\033[1m\" + \"strings:\" + \"\\033[0m\")\n",
    "    print(test[\"strings\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392ee3d",
   "metadata": {},
   "source": [
    "## 6. Calculating false positive rate\n",
    "\n",
    "**Note: We can only calculate the false positive rate for cases 1 and 2, not 3 or 4. The .npz files that are used in the demonstration below contain case 3 and 4 data in addition to case 1 and 2 data, so this would not be a correct calculation.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1e7e9469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def false_positive_rate(subset, file_names):\n",
    "    # Use the subset adjacency matrix to create a dictionary\n",
    "    columns = np.array(subset.columns)\n",
    "    dictionary = dict(enumerate(columns.flatten(), 1))\n",
    "    dictionary = dict((value, key) for key, value in dictionary.items()) # Swap the keys and values\n",
    "    \n",
    "    # Define a sorting function that sorts using the dictionary\n",
    "    def sorting_function(input_string):\n",
    "        my_list = input_string\n",
    "        my_list = sorted(my_list, key = lambda x : dictionary[x.split(\",\")[0]])  \n",
    "        my_list = sorted(my_list, key = lambda x : float(x.split(\",\")[1].split(\"=\")[-1]), reverse = True) \n",
    "        return my_list\n",
    "    \n",
    "    # False positive rate calculation\n",
    "    count = 0\n",
    "    for i in range(0, len(file_names) - 1):\n",
    "        reject_p = np.zeros(len(columns)) # For each repeat, assume no structures are affected (null hypothesis)\n",
    "        file = np.load(file_names[i])\n",
    "        file = file[\"strings\"] # Values corresponding to the key\n",
    "        file = sorting_function(file)\n",
    "        \n",
    "        for j in range(0, len(columns) - 1): # For each structure in each repeat...\n",
    "            p = file[j].find(\"p=\") # Index of \"p\" in the string\n",
    "            pval = float(file[j][p::][2::]) # Extract the p-value\n",
    "            if pval < 0.05: # If the p-value is < 0.05...\n",
    "                reject_p[j] = 1\n",
    "            else: # The test statistic is the probabilities, which were sorted, so stop after the first structure we fail to reject\n",
    "                break\n",
    "                \n",
    "        if any(reject_p > 0): # If there's at least one structure with p < 0.05...\n",
    "            count += 1 # Add 1 to the false positive count\n",
    "                \n",
    "    return (count / 1000)\n",
    "    \n",
    "\n",
    "false_positive_rate(subset, file_names = [\"test1.npz\", \"test2.npz\", \"test3.npz\", \"test4.npz\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00990428",
   "metadata": {},
   "source": [
    "## 7. Calculating false negative rate\n",
    "\n",
    "**Note: We can only calculate the false negative rate for cases 2, 3, and 4, not case 1. The .npz files that are used in the demonstration below contain case 1 data in addition to case 2, 3, and 4 data, so this would not be a correct calculation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "155d8e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def false_negative_rate(subset, file_names):\n",
    "    # Use the subset adjacency matrix to create a dictionary\n",
    "    columns = np.array(subset.columns)\n",
    "    dictionary = dict(enumerate(columns.flatten(), 1))\n",
    "    dictionary = dict((value, key) for key, value in dictionary.items()) # Swap the keys and values\n",
    "    \n",
    "    # Define a sorting function that sorts using the dictionary\n",
    "    def sorting_function(input_string):\n",
    "        my_list = input_string\n",
    "        my_list = sorted(my_list, key = lambda x : dictionary[x.split(\",\")[0]])  \n",
    "        my_list = sorted(my_list, key = lambda x : float(x.split(\",\")[1].split(\"=\")[-1]), reverse = True) \n",
    "        return my_list\n",
    "    \n",
    "    # Create a counter for each structure\n",
    "    counters = [] # Empty list to be filled\n",
    "    for k in range(0, len(columns)): # For each structure in each repeat...\n",
    "        counters.append(0) # List of counters, one entry for each structure, each counter starts at 0\n",
    "    \n",
    "    # False negative rate calculation\n",
    "    for i in range(0, len(file_names) - 1):\n",
    "        reject_p = np.zeros(len(columns)) # For each repeat, assume no structures are affected (null hypothesis)\n",
    "        file = np.load(file_names[i])\n",
    "        file = file[\"strings\"] # Values corresponding to the key\n",
    "        file = sorting_function(file)\n",
    "    \n",
    "        for j in range(0, len(columns) - 1): # For each structure in each repeat...\n",
    "            p = file[j].find(\"p=\") # Index of \"p\" in the string\n",
    "            pval = float(file[j][p::][2::]) # Extract the p-value\n",
    "            if pval < 0.05: # If the p-value is < 0.05...\n",
    "                reject_p[j] = 1\n",
    "            else: # The test statistic is the probabilities, which were sorted, so stop after the first structure we fail to reject\n",
    "                break\n",
    "        \n",
    "        if case == 3: # Go through every structure since both hippocampus and amygdala are affected\n",
    "            for k in range(0, len(columns)): # For each structure in each repeat...\n",
    "                for r, s in zip(reject_p, file):\n",
    "                    if columns[k] in s and r: # If a given structure name is in the string and we decided to reject H0...\n",
    "                        counters[k] += 1\n",
    "                    elif not r: # As soon as we fail to reject one structure, stop\n",
    "                        break\n",
    "        elif case == 2:\n",
    "            case_2_structures = []\n",
    "    \n",
    "    \n",
    "false_negative_rate(subset, file_names = [\"test1.npz\", \"test2.npz\", \"test3.npz\", \"test4.npz\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822490c1",
   "metadata": {},
   "source": [
    "**Question 1: Does the order of adding to each counter matter?**\n",
    "\n",
    "Currently, in my `false_negative_rate()` function, the order of adding to each counter is the order of structures in the subset adjacency matrix. In my previous false negative rate calculations, the order of structures was slightly different.\n",
    "\n",
    "The first bullet point is the order in my function. The second bullet point is the order in my previous calculation.\n",
    "\n",
    "* Everything, Telencephalon_L_501_5, CerebralCortex_L_482_4, Limbic_L_434_3, Hippo_L_338_2, Amyg_L_336_2, Hippo_L_75_1, Amyg_L_73_1\n",
    "* Everything, Telencephalon_L_501_5, CerebralCortex_L_482_4, Limbic_L_434_3, Hippo_L_338_2, Hippo_L_75_1, Amyg_L_336_2, Amyg_L_73_1\n",
    "\n",
    "The reason I'm wondering is because in my previous calculation, I knew which structures were included in the subset, so then I manually ordered them. In this function that I'm making, I want to make it general, so that's why I wanted to use the order of structures from the input subset adjacency matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88775c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
